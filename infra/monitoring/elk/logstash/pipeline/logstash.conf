input {
  # TCP input for application logs
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp"]
  }

  # Beats input for Filebeat
  beats {
    port => 5044
    tags => ["filebeat"]
  }

  # Syslog input
  syslog {
    port => 5514
    tags => ["syslog"]
  }
}

filter {
  # Parse MT4 market data logs
  if "market_data" in [tags] {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{WORD:log_level} - %{DATA:logger} - %{GREEDYDATA:message}"
      }
    }
    
    # Extract market data specifics
    if [logger] == "MarketDataBridge" {
      grok {
        match => {
          "message" => "\\[%{WORD:event_type}\\] %{WORD:symbol} Bid: %{NUMBER:bid:float} Ask: %{NUMBER:ask:float}"
        }
        tag_on_failure => []
      }
    }
    
    # Parse statistics
    if "statistics" in [message] {
      json {
        source => "message"
        target => "stats"
      }
    }
  }

  # Parse ZeroMQ logs
  if "zeromq" in [tags] {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{WORD:log_level} - %{DATA:component} - %{GREEDYDATA:message}"
      }
    }
    
    # Extract ZeroMQ metrics
    if "Publisher bound to" in [message] {
      grok {
        match => {
          "message" => "Publisher bound to %{URI:bind_address}"
        }
        tag_on_failure => []
      }
    }
  }

  # Parse security events
  if "security" in [tags] {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{WORD:log_level} - %{DATA:component} - %{GREEDYDATA:message}"
      }
    }
    
    # Extract security events
    if "CURVE security enabled" in [message] {
      mutate {
        add_field => { "security_event" => "curve_enabled" }
      }
    }
    
    if "Generated" in [message] and "keys" in [message] {
      grok {
        match => {
          "message" => "Generated %{WORD:key_type} keys"
        }
        tag_on_failure => []
      }
      mutate {
        add_field => { "security_event" => "key_generation" }
      }
    }
  }

  # Parse Docker container logs
  if [docker] {
    # Extract container info
    mutate {
      add_field => {
        "container_name" => "%{[docker][container][name]}"
        "container_id" => "%{[docker][container][id]}"
      }
    }
  }

  # Add common fields
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:production}"
      "application" => "mt4-docker"
    }
  }

  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      tag_on_failure => ["_jsonparsefailure"]
    }
  }

  # Convert timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Remove processed fields
  mutate {
    remove_field => [ "host", "port" ]
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "mt4-logs-%{+YYYY.MM.dd}"
    template_name => "mt4-logs"
    template => "/usr/share/logstash/templates/mt4-logs.json"
    template_overwrite => true
  }

  # Debug output (disable in production)
  # stdout {
  #   codec => rubydebug
  # }

  # Alert on errors
  if [log_level] == "ERROR" {
    # Could send to alerting system
    # email {
    #   to => "alerts@example.com"
    #   subject => "MT4 Error: %{message}"
    # }
  }
}